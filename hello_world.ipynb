{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hello_world.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nevercomes/MDeepLearning/blob/ipynb/hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "V8jiFzcg193i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Built model"
      ]
    },
    {
      "metadata": {
        "id": "CViFXhErsMSI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import data from external sources\n",
        "Import the terget image from google cloud storage:"
      ]
    },
    {
      "metadata": {
        "id": "Th2sSQYKsnwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f33df11d-8ce0-493d-dd51-416559e5b880"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RGsVDh2MPKv3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "\n",
        "# image = Image.open('/content/gdrive/My Drive/Colab Notebooks/pic2code/helloWorld_version/dataset/hw_img.png')\n",
        "# image.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hn4UDHPtCkr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import API"
      ]
    },
    {
      "metadata": {
        "id": "V1eevS6tmT3d",
        "colab_type": "code",
        "outputId": "1616c70e-fc2c-4f2c-a816-792ed3236d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)\n",
        "print(np.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n",
            "2.1.6-tf\n",
            "1.14.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-wbb224JVmIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "# from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A_1E_RTJWhnH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "# from keras.layers import RepeatVector\n",
        "\n",
        "from keras.engine.input_layer import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P_BaCueB5nGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.backend import concatenate\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RbjIWYgU-Ur8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.core import RepeatVector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AipdufNbtIQ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Preprocess the input image"
      ]
    },
    {
      "metadata": {
        "id": "asX9kHQDnJm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dde8387d-520c-4f34-94b0-7b77d26857db"
      },
      "cell_type": "code",
      "source": [
        "# length of longest sentence\n",
        "max_caption_len = 3\n",
        "# size of vocabulary\n",
        "vocab_size = 3\n",
        "\n",
        "# load one screenshot for each word and turn them into digits\n",
        "images = []\n",
        "# the image comes from my google cloud storage\n",
        "image = '/content/gdrive/My Drive/Colab Notebooks/pic2code/\\\n",
        "helloWorld_version/dataset/hw_img.png'\n",
        "# image = Image.open(image)\n",
        "image = load_img(image, target_size=(224,224))\n",
        "w = 224\n",
        "h = 224\n",
        "c = 3\n",
        "# image.resize((224,224))\n",
        "# image.reshape(-1,w,h,c)\n",
        "\n",
        "\n",
        "for i in range(2):\n",
        "  image_array = img_to_array(image)\n",
        "  print(image_array.shape)\n",
        "  images.append(image_array)\n",
        "images = np.array(images, dtype=float)\n",
        "# preprocess input for the VGG16 model\n",
        "images = preprocess_input(images)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mAuavj80oYvH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** img_to_array: ** from *Keras.preprocessing.image*, converting images to arrays.\n",
        "- target: or target_size, resize the image to target size.  \n",
        "\n",
        "**VGG16 Model:**"
      ]
    },
    {
      "metadata": {
        "id": "eyI6_6hNtRlD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Perprocess the tokens"
      ]
    },
    {
      "metadata": {
        "id": "X_6COeNJtRDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# turn start tokens into one-hot encoding\n",
        "html_input = np.array(\n",
        "                [[[0., 0., 0.], #start\n",
        "                 [0., 0., 0.],\n",
        "                 [1., 0., 0.]],\n",
        "                 [[0., 0., 0.], #start <HTML>Hello World!</HTML>\n",
        "                 [1., 0., 0.],\n",
        "                 [0., 1., 0.]]])\n",
        "# turn next word into one-hot encoding\n",
        "next_words = np.array(\n",
        "                [[0., 1., 0.], # <HTML>Hello World!</HTML>\n",
        "                 [0., 0., 1.]]) # end"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rntk-VgRu65j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Extract features by VGG16 trained on imageNet"
      ]
    },
    {
      "metadata": {
        "id": "pfREyrSyvDlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7cd6ab17-7744-405d-e00a-32a01cb319d1"
      },
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model trained on imagenet and output the classification feature\n",
        "VGG = VGG16(weights='imagenet', include_top=True)\n",
        "# Extract the features from the image\n",
        "features = VGG.predict(images)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "un136WamwiQs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load the feature to the network"
      ]
    },
    {
      "metadata": {
        "id": "sROq6KV4wnKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the feature to the network, apply a dense layer, and repeat the vector\n",
        "vgg_feature = Input(shape=(1000,))\n",
        "vgg_feature_dense = Dense(5)(vgg_feature)\n",
        "# keras.layers.RepeatVector(n) Repeats the input n times.\n",
        "vgg_feature_repeat = RepeatVector(max_caption_len)(vgg_feature_dense)\n",
        "# Extract information from the input seqence \n",
        "language_input = Input(shape=(vocab_size, vocab_size))\n",
        "language_model = LSTM(5, return_sequences=True)(language_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IG30DHIwLvu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "在keras中，数据是以张量的形式表示的，张量的形状称之为shape，表示从最外层向量逐步到达最底层向量的降维解包过程。比如，一个一阶的张量[1,2,3]的shape是(3,);\n",
        "一个二阶的张量[[1,2,3],[4,5,6]]的shape是(2,3);一个三阶的张量[[[1],[2],[3]],[[4],[5],[6]]]的shape是(2,3,1)。\n",
        "\n",
        "input_shape就是指输入张量的shape。例如，input_dim=784，说明输入是一个784维的向量，这相当于一个一阶的张量，它的shape就是(784,)。因此，input_shape=(784,)。\n",
        "\n",
        "input_dim = input_shape(input_dim,)\n",
        "\n",
        "input_dim, input_length = input_shape(input_length, input_dim)"
      ]
    },
    {
      "metadata": {
        "id": "Hr5yZKil0dfY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Concatenate, extract and predict"
      ]
    },
    {
      "metadata": {
        "id": "HQl00FJc0jKu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Concatenate the information from the image and the input\n",
        "decoder = concatenate([vgg_feature_repeat, language_model])\n",
        "# Extract information from the concatenated output\n",
        "decoder = LSTM(5, return_sequences=False)(decoder)\n",
        "# Predict which word comes next\n",
        "decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
        "\n",
        "# Compile and run the neural network\n",
        "model = Model(inputs=[vgg_feature, language_input], outputs=decoder_output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVs0G18q0oRm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "keras.backend.concatenate(tensors, axis=-1)  \n",
        "Concatenates a list of tensors alongside the specified axis.  \n",
        "\n",
        "**Arguments**\n",
        "\n",
        "tensors: list of tensors to concatenate.\n",
        "axis: concatenation axis.    \n",
        "\n",
        "**Returns  **\n",
        "\n",
        "A tensor."
      ]
    },
    {
      "metadata": {
        "id": "4PpCfCFH1cEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8qEXEy8FAzne",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the neural network\n",
        "model.fit([features, html_input], next_words, batch_size=2, \n",
        "          shuffle=False, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pe4ckzG0B_Dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1053
        },
        "outputId": "ad9dc7d5-7d5f-478f-bdc2-cf7a1070c64b"
      },
      "cell_type": "code",
      "source": [
        "    #Length of longest sentence\n",
        "    max_caption_len = 3\n",
        "    #Size of vocabulary \n",
        "    vocab_size = 3\n",
        "    \n",
        "    # Load one screenshot for each word and turn them into digits \n",
        "    images = []\n",
        "    for i in range(2):\n",
        "        images.append(img_to_array(load_img('/content/gdrive/My Drive/Colab Notebooks/pic2code/helloWorld_version/dataset/hw_img.png', target_size=(224, 224))))\n",
        "    images = np.array(images, dtype=float)\n",
        "    # Preprocess input for the VGG16 model\n",
        "    images = preprocess_input(images)\n",
        "    \n",
        "    #Turn start tokens into one-hot encoding\n",
        "    html_input = np.array(\n",
        "                [[[0., 0., 0.], #start\n",
        "                 [0., 0., 0.],\n",
        "                 [1., 0., 0.]],\n",
        "                 [[0., 0., 0.], #start <HTML>Hello World!</HTML>\n",
        "                 [1., 0., 0.],\n",
        "                 [0., 1., 0.]]])\n",
        "    \n",
        "    #Turn next word into one-hot encoding\n",
        "    next_words = np.array(\n",
        "                [[0., 1., 0.], # <HTML>Hello World!</HTML>\n",
        "                 [0., 0., 1.]]) # end\n",
        "    \n",
        "    # Load the VGG16 model trained on imagenet and output the classification feature\n",
        "    VGG = VGG16(weights='imagenet', include_top=True)\n",
        "    # Extract the features from the image\n",
        "    features = VGG.predict(images)\n",
        "    \n",
        "    #Load the feature to the network, apply a dense layer, and repeat the vector\n",
        "    vgg_feature = Input(shape=(1000,))\n",
        "    vgg_feature_dense = Dense(5)(vgg_feature)\n",
        "    vgg_feature_repeat = RepeatVector(max_caption_len)(vgg_feature_dense)\n",
        "    # Extract information from the input seqence \n",
        "    language_input = Input(shape=(vocab_size, vocab_size))\n",
        "    language_model = LSTM(5, return_sequences=True)(language_input)\n",
        "    \n",
        "    # Concatenate the information from the image and the input\n",
        "    decoder = concatenate([vgg_feature_repeat, language_model])\n",
        "    # Extract information from the concatenated output\n",
        "    decoder = LSTM(5, return_sequences=False)(decoder)\n",
        "    # Predict which word comes next\n",
        "    decoder_output = Dense(vocab_size, activation='softmax')(decoder)\n",
        "    # Compile and run the neural network\n",
        "    model = Model(inputs=[vgg_feature, language_input], outputs=decoder_output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "    \n",
        "    # Train the neural network\n",
        "    model.fit([features, html_input], next_words, batch_size=2, shuffle=False, epochs=1000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a2f49ea39f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Compile and run the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvgg_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 231\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m                   tensor_index=tensor_index)\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1353\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1353\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \"\"\"\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;31m# Prevent cycles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iRZfUCjA2Der",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make prediction"
      ]
    },
    {
      "metadata": {
        "id": "rgaQU23DMPfn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get the output one by one, and splice for sentence to feed into the network manually."
      ]
    },
    {
      "metadata": {
        "id": "HbK-8aqx2GTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an empty sentence and insert the start token\n",
        "sentence = np.zeros((1, 3, 3)) # [[0,0,0], [0,0,0], [0,0,0]]\n",
        "start_token = [1., 0., 0.] # start\n",
        "sentence[0][2] = start_token # place start in empty sentence\n",
        "    \n",
        "# Making the first prediction with the start token\n",
        "second_word = model.predict([np.array([features[1]]), sentence])\n",
        "    \n",
        "# Put the second word in the sentence and make the final prediction\n",
        "sentence[0][1] = start_token\n",
        "sentence[0][2] = np.round(second_word)\n",
        "third_word = model.predict([np.array([features[1]]), sentence])\n",
        "    \n",
        "# Place the start token and our two predictions in the sentence \n",
        "sentence[0][0] = start_token\n",
        "sentence[0][1] = np.round(second_word)\n",
        "sentence[0][2] = np.round(third_word)\n",
        "    \n",
        "# Transform our one-hot predictions into the final tokens\n",
        "vocabulary = [\"start\", \"<HTML><center><H1>Hello World!</H1></center></HTML>\", \"end\"]\n",
        "for i in sentence[0]:\n",
        "    print(vocabulary[np.argmax(i)], end=' ')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}